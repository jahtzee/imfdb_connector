{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>IMFDB Connector</h1>\n",
    "<h3>Python script for populating a PostgreSQL database with article data from the Internet Movies and Firearms Database Wiki</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2446,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import psycopg2\n",
    "import requests\n",
    "import os\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd #1.20 or above required\n",
    "import time\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2447,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Establish a connection to the database\n",
    "cnx = psycopg2.connect(\n",
    "    host=\"localhost\",\n",
    "    user=\"imfdb\",\n",
    "    password=os.environ.get(\"PG_IMFDB_PASSWORD\"),\n",
    "    database=\"imfdb\"\n",
    ")\n",
    "\n",
    "# Create a cursor object\n",
    "cursor = cnx.cursor()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> MediaWiki API related functions</h3>\n",
    "These are used to query the MW API for article data and populating the Postgres DB with the minimum necessary data for further processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2448,
   "metadata": {},
   "outputs": [],
   "source": [
    "def api_request(url):\n",
    "    # Makes a get request to the specified API endpoint. A JSON response is expected.\n",
    "\n",
    "    # Make a GET request to the IMFDB API endpoint\n",
    "    response = requests.get(url)\n",
    "\n",
    "    # Check if the request was successful\n",
    "    if response.status_code == 200:\n",
    "        # Get the JSON data from the response\n",
    "        return response.json()\n",
    "    else:\n",
    "        # Handle the error\n",
    "        print(f\"ERROR: api_request(): Request failed with status code: {response.status_code}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2449,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_page_by_id(pageid, prop, format):\n",
    "    # Example: parse_page_by_id(\"215875\",\"text\", \"json\") to parse the wiki text of Weird Al Yankovic as json\n",
    "\n",
    "    data = api_request(f\"https://www.imfdb.org/api.php?action=parse&pageid={pageid}&prop={prop}&format={format}\")\n",
    "\n",
    "    # Error Handling\n",
    "    if data is None:\n",
    "        print(\"ERROR: parse_page_by_id(): Data is None!\")\n",
    "        return None\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2450,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_page_id_by_url(url, format):\n",
    "    # url must take the form of '/wiki/Elke_Sommer'\n",
    "    if url is None:\n",
    "        print(f\"ERROR: get_page_id_by_url(): url was None!\")\n",
    "        return None\n",
    "    title = None\n",
    "    match = re.match(r\"^(\\/wiki\\/)(.*)$\", url)\n",
    "    if match:\n",
    "        title = match.group(2)\n",
    "        if \"#\" in title: # HTML anchors need to be stripped\n",
    "            title = title.split(\"#\")[0].strip()\n",
    "\n",
    "    if title is None:\n",
    "        print(f\"ERROR: get_page_id_by_url(): No title could be found for url '{url}'!\")\n",
    "        return None\n",
    "    data = api_request(f\"https://www.imfdb.org/api.php?action=query&titles={title}&format={format}\")\n",
    "    if data is None:\n",
    "        print(f\"ERROR: get_page_id_by_url(): Data is None for url '{url}'!\")\n",
    "        return None\n",
    "    if (len(data[\"query\"][\"pages\"]) > 1):\n",
    "        print(f\"ERROR: get_page_id_by_url(): More than one page was returned for '{url}'!\")\n",
    "        return None\n",
    "    for value in data[\"query\"][\"pages\"]:\n",
    "        pageid = value\n",
    "    return pageid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2451,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_page_text_by_id(pageid):\n",
    "    response = requests.get(f\"https://www.imfdb.org/index.php?curid={pageid}\")\n",
    "    return str(response.text)\n",
    "# We don't use the API anymore for this due to issues with the HTML it responds with\n",
    "#def get_page_text_by_id(pageid):\n",
    "#    data = parse_page_by_id(pageid, \"text\", \"json\")\n",
    "#    return str(data[\"parse\"][\"text\"][\"*\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2452,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_categorymembers(cmtitle, format):\n",
    "    # Example: query_categorymembers(\"Category:Actor\", \"json\") to query all actor pages as json.\n",
    "\n",
    "    # Make a GET request to the IMFDB API endpoint\n",
    "    data = api_request(f\"https://www.imfdb.org/api.php?action=query&list=categorymembers&cmtitle={cmtitle}&format={format}\")\n",
    "\n",
    "    # Error Handling\n",
    "    if data is None:\n",
    "        print(\"ERROR: query_categorymembers(): Data is None!\")\n",
    "        return None\n",
    "\n",
    "    #Initialize list\n",
    "    categorymembers = []\n",
    "\n",
    "    # Loop through the first batch of category members\n",
    "    for member in data[\"query\"][\"categorymembers\"]:\n",
    "        print(f\"DEBUG: query_categorymembers(): Adding {member['title']}\")\n",
    "        categorymembers.append(member)\n",
    "\n",
    "    # Continue fetching while there is something to be fetched\n",
    "    while \"continue\" in data:\n",
    "        data = api_request(f\"https://www.imfdb.org/api.php?action=query&list=categorymembers&cmtitle={cmtitle}&format={format}&cmcontinue={data['continue']['cmcontinue']}\")\n",
    "        \n",
    "        # Error Handling\n",
    "        if data is None:\n",
    "            print(f\"ERROR: query_categorymembers(): Data is None in continuation batch {data['continue']['cmcontinue']}\")\n",
    "            return None\n",
    "            \n",
    "        # Loop through continuation batch:\n",
    "        for member in data[\"query\"][\"categorymembers\"]:\n",
    "            print(f\"DEBUG: query_categorymembers(): Adding {member['title']}\")\n",
    "            categorymembers.append(member)\n",
    "\n",
    "    return categorymembers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2453,
   "metadata": {},
   "outputs": [],
   "source": [
    "def populate_actors_table():\n",
    "    actors = query_categorymembers(\"Category:Actor\", \"json\")\n",
    "\n",
    "    for actor in actors:\n",
    "\n",
    "        actorpageid = str(actor['pageid'])\n",
    "        actorurl = f\"https://www.imfdb.org/index.php?curid={actorpageid}\"\n",
    "        actorpagecontent = get_page_text_by_id(actorpageid)\n",
    "        actorname = str(actor['title'])\n",
    "        if \"Category:\" in actorname:\n",
    "            continue\n",
    "        print(f\"INSERTing: {actorname}, {actorpageid}\")\n",
    "        statement = \"INSERT INTO actors (actorurl, actorpageid, actorpagecontent, actorname) VALUES (%s, %s, %s, %s)\"\n",
    "        cursor.execute(statement, (actorurl, actorpageid, actorpagecontent, actorname))\n",
    "    \n",
    "    cnx.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2454,
   "metadata": {},
   "outputs": [],
   "source": [
    "def populate_movies_table():\n",
    "    movies = query_categorymembers(\"Category:Movie\", \"json\")\n",
    "\n",
    "    for movie in movies:\n",
    "\n",
    "        moviepageid = str(movie['pageid'])\n",
    "        movieurl = f\"https://www.imfdb.org/index.php?curid={moviepageid}\"\n",
    "        moviepagecontent = get_page_text_by_id(moviepageid)\n",
    "        movietitle = str(movie['title'])\n",
    "        if \"Category:\" in movietitle:\n",
    "            continue\n",
    "        print(f\"DEBUG: populate_movies_table(): INSERTing {movietitle}, {moviepageid}\")\n",
    "        statement = \"INSERT INTO movies (movieurl, moviepageid, moviepagecontent, movietitle) VALUES (%s, %s, %s, %s)\"\n",
    "        cursor.execute(statement, (movieurl, moviepageid, moviepagecontent, movietitle))\n",
    "    \n",
    "    cnx.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2455,
   "metadata": {},
   "outputs": [],
   "source": [
    "def populate_tvseries_table():\n",
    "    tvseries = query_categorymembers(\"Category:Television\", \"json\")\n",
    "\n",
    "    for series in tvseries:\n",
    "\n",
    "        tvseriespageid = str(series['pageid'])\n",
    "        tvseriesurl = f\"https://www.imfdb.org/index.php?curid={tvseriespageid}\"\n",
    "        tvseriespagecontent = get_page_text_by_id(tvseriespageid)\n",
    "        tvseriestitle = str(series['title'])\n",
    "        if \"Category:\" in tvseriestitle:\n",
    "            continue\n",
    "        print(f\"INSERTing: {tvseriestitle}, {tvseriespageid}\")\n",
    "        statement = \"INSERT INTO tvseries (tvseriesurl, tvseriespageid, tvseriespagecontent, tvseriestitle) VALUES (%s, %s, %s, %s)\"\n",
    "        cursor.execute(statement, (tvseriesurl, tvseriespageid, tvseriespagecontent, tvseriestitle))\n",
    "    \n",
    "    cnx.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2456,
   "metadata": {},
   "outputs": [],
   "source": [
    "def populate_firearms_table_minimally():\n",
    "    firearms = query_categorymembers(\"Category:Gun\", \"json\")\n",
    "\n",
    "    for firearm in firearms:\n",
    "\n",
    "        firearmpageid = str(firearm['pageid'])\n",
    "        firearmurl = f\"https://www.imfdb.org/index.php?curid={firearmpageid}\"\n",
    "        firearmpagecontent = get_page_text_by_id(firearmpageid)\n",
    "        firearmtitle = str(firearm['title'])\n",
    "        if \"Category:\" in firearmtitle:\n",
    "            continue\n",
    "        print(f\"DEBUG: populate_firearms_table_minimally(): INSERTing {firearmtitle}, {firearmpageid}\")\n",
    "        statement = \"INSERT INTO firearms (firearmurl, firearmpageid, firearmpagecontent, firearmtitle) VALUES (%s, %s, %s, %s)\"\n",
    "        cursor.execute(statement, (firearmurl, firearmpageid, firearmpagecontent, firearmtitle))\n",
    "    \n",
    "    cnx.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2457,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_firearm_html_by_uuid(uuid):\n",
    "    # Use with care! This will break multis because it pulls html from the online article in IMFDB! \n",
    "    statement = \"SELECT firearmpageid FROM firearms WHERE firearmid = %s\"\n",
    "    cursor.execute(statement, (uuid,))\n",
    "    if cursor.rowcount == 1:\n",
    "        firearmpageid = cursor.fetchone()[0]\n",
    "        firearmpagecontent = get_page_text_by_id(firearmpageid)\n",
    "        print(f\"DEBUG: update_firearm_html_by_uuid(): UPDATING html for {uuid}\")\n",
    "        statement = \"UPDATE firearms SET firearmpagecontent = %s WHERE firearmid = %s\"\n",
    "        cursor.execute(statement, (firearmpagecontent, uuid,))\n",
    "        cnx.commit()\n",
    "    else:\n",
    "        print(f\"ERROR: update_firearm_html_by_uuid(): Can not update. Unexpected number of rows returned for {uuid}!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2458,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_redirects_by_pageid(pageid):\n",
    "    data = api_request(f\"https://www.imfdb.org/api.php?action=query&prop=redirects&pageids={pageid}&format=json\")\n",
    "\n",
    "    redirects = {}\n",
    "\n",
    "    for page in data[\"query\"][\"pages\"]:\n",
    "        if \"redirects\" not in data[\"query\"][\"pages\"][page]:\n",
    "            return None\n",
    "        for redirect in data[\"query\"][\"pages\"][page][\"redirects\"]:\n",
    "            redirects[redirect[\"pageid\"]] = redirect[\"title\"]\n",
    "\n",
    "    return redirects "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2459,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_disambiguation_page(link):\n",
    "    response = requests.get(f\"https://www.imfdb.org/{link}\")\n",
    "    soup = BeautifulSoup(str(response.text), 'html.parser')\n",
    "\n",
    "    catlinks = soup.find_all('div', class_='mw-normal-catlinks')\n",
    "    if catlinks is not None:\n",
    "        for child in catlinks[0].children:\n",
    "            # check if the child element is an <ul>\n",
    "            if child.name == 'ul':\n",
    "                # loop through each <li> in the <ul>\n",
    "                for li in child.find_all('li'):\n",
    "                    # check if the <li> contains an <a> with href = '/wiki/Category:Disambiguation_pages'\n",
    "                    if li.find('a', href='/wiki/Category:Disambiguation_pages'):\n",
    "                        return True\n",
    "\n",
    "    h1 = soup.find_all('h1')\n",
    "    if h1 is not None:\n",
    "        if \"(disambiguation)\" in h1[0].text:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "    else:\n",
    "        print(f\"ERROR: is_disambiguation_page(): Page does not contain an h1 element.\")\n",
    "    print(f\"ERROR: is_disambiguation_page(): Check failed.\")\n",
    "    #print(response.text)\n",
    "    return None"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Database related functions</h3>\n",
    "Once we have downloaded the necessary article data, we extract useful information from the HTML to fill the rest of our column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2460,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dicts and lists #\n",
    "actor_false_positives = [\"\",\"(uncredited)\", \"(Uncredited)\", \"Uncredited\", \"uncredited\", \".\", \"various\", \"Various\", \"Unknown\", \"unknown\", \"various\", \"Various\", \"multiple\",\"multiple\",\n",
    "                         \"—\", \"Multiple actors\", \"-\", \"varios actors\", \"multiple actors\", \"Various others\", \"Varios Actors\", \"Various thugs\", \"Various extras\", \"Curtis Taylor, Various actors\",\n",
    "                         \"Various Actors\", \"Various actors\", \"Various characters\", \"Various\", \"various actors\", \"Multiple actors\", \"uncredited actor\"]\n",
    "\n",
    "firearms_dict = {\n",
    "    \"firearmid\" : 0,\n",
    "    \"firearmurl\" : 1,\n",
    "    \"parentfirearmid\" : 2,\n",
    "    \"firearmpageid\" : 3,\n",
    "    \"firearmpagecontent\" : 4,\n",
    "    \"specificationid\" : 5,\n",
    "    \"firearmtitle\" : 6,\n",
    "    \"firearmversion\" : 7,\n",
    "    \"isfamily\" : 8,\n",
    "    \"isfictional\" : 9\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2461,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_page_content_from_db(pageid, table):\n",
    "    # This only works with firearms that are NOT children\n",
    "    if table in [\"tvseries\"]:\n",
    "        content = \"{}pagecontent\".format(table)\n",
    "        id = \"{}id\".format(table)\n",
    "    elif table in [\"actors\", \"movies\", \"firearms\"]:\n",
    "        singular = table.rstrip(\"s\")\n",
    "        content = \"{}pagecontent\".format(singular)\n",
    "        id = \"{}id\".format(singular)\n",
    "    else:\n",
    "        print(\"ERROR: get_page_content_from_db(): {} is not a valid table!\".format(table))\n",
    "        return None\n",
    "\n",
    "    statement = \"select {} from {} where {} = '{}';\".format(content, table, id, pageid)\n",
    "    if table == \"firearms\": # If the firearms table is queried, filter out child firearm rows\n",
    "        statement = f\"select {content} from firearms where {id} = '{pageid}' and parentfirearmid is null;\"\n",
    "    cursor.execute(statement)\n",
    "    return cursor.fetchone()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2462,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_page_content_from_db_by_uuid(uuid, table):\n",
    "    # This works with all pages, including firearm children, but takes the uuid as key\n",
    "    if table in [\"tvseries\"]:\n",
    "        content = \"{}pagecontent\".format(table)\n",
    "        id = \"{}id\".format(table)\n",
    "    elif table in [\"actors\", \"movies\", \"firearms\"]:\n",
    "        singular = table.rstrip(\"s\")\n",
    "        content = \"{}pagecontent\".format(singular)\n",
    "        id = \"{}id\".format(singular)\n",
    "    else:\n",
    "        print(\"ERROR: get_page_content_from_db(): {} is not a valid table!\".format(table))\n",
    "        return None\n",
    "\n",
    "    statement = \"select {} from {} where {} = '{}';\".format(content, table, id, uuid)\n",
    "    cursor.execute(statement)\n",
    "    return cursor.fetchone()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2463,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_firearms_isfictional():\n",
    "    statement = \"UPDATE firearms SET isfictional = FALSE WHERE NOT firearmtitle LIKE '(%) -%';\"\n",
    "    cursor.execute(statement)\n",
    "    statement = \"UPDATE firearms SET isfictional = TRUE WHERE firearmtitle LIKE '(%) -%';\"\n",
    "    cursor.execute(statement)\n",
    "    cnx.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2464,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_multi_gun_page(pageid):\n",
    "    # Exceptions\n",
    "    if (pageid == \"464719\" or pageid == \"314208\"): #Both of these have a table of contents despite being singles\n",
    "        return False\n",
    "\n",
    "    # If there are multiple h1s in an article, which are not See Also or Specification, it's a multi-gun page\n",
    "    soup = soup = BeautifulSoup(get_page_content_from_db(pageid, \"firearms\"), 'html.parser')\n",
    "\n",
    "    toctitle = soup.find(\"div\", class_=\"toctitle\") #If there is no table of contents, we don't need to check further, it's not multi-gun\n",
    "    if toctitle is None:\n",
    "        return False\n",
    "\n",
    "    see_also = soup.find(id = \"See_Also\")\n",
    "    if see_also is not None:\n",
    "        if see_also.parent.name == \"h1\":\n",
    "            see_also.parent.extract()\n",
    "\n",
    "    spec = soup.find(id = \"Specifications\")\n",
    "    if spec is not None:\n",
    "        if spec.parent.name == \"h1\":\n",
    "            spec.parent.extract()\n",
    "\n",
    "    h1_tags = soup.find_all(\"h1\")\n",
    "    count = len(h1_tags)\n",
    "\n",
    "    if count > 1:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2465,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_firearms_isfamily():\n",
    "    # We assume a firearm is a family when it is named 'series' or has a multi-gun page\n",
    "    keyword1 = \"series\"\n",
    "    keyword2 = \"Series\"\n",
    "    statement = \"UPDATE firearms set isfamily = FALSE WHERE NOT (firearmtitle LIKE '%%%s%%' OR firearmtitle LIKE '%%%s%%' OR firearmtitle = 'Air Guns')\" % (keyword1, keyword2)\n",
    "    cursor.execute(statement)\n",
    "    statement = \"UPDATE firearms set isfamily = TRUE WHERE (firearmtitle LIKE '%%%s%%' OR firearmtitle LIKE '%%%s%%' OR firearmtitle = 'Air Guns')\" % (keyword1, keyword2)\n",
    "    cursor.execute(statement)\n",
    "\n",
    "    statement = \"SELECT * FROM firearms\"\n",
    "    cursor.execute(statement)\n",
    "    firearms = cursor.fetchall()\n",
    "    for firearm in firearms:\n",
    "        if (is_multi_gun_page(pageid=firearm[3]) and firearm[8] == False): # If we have determined the article is multi-gun, it's a family\n",
    "            statement = \"UPDATE firearms set isfamily = TRUE WHERE firearmid = '%s'\" % (firearm[0])\n",
    "            cursor.execute(statement)\n",
    "        if firearm[2] is not None: # Child firearms are never families \n",
    "            statement = \"UPDATE firearms set isfamily = FALSE WHERE firearmid = '%s'\" % (firearm[0])\n",
    "            cursor.execute(statement)\n",
    "\n",
    "    cnx.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2466,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_number_of_specifications(html_content):\n",
    "    soup = BeautifulSoup(html_content, 'html.parser')\n",
    "    \n",
    "    spec_tags = soup.find_all(id=lambda value: value and value.startswith(\"Specifications\"))\n",
    "    spec_count = len(spec_tags)\n",
    "\n",
    "    print(\"The number of h2 tags with 'Specifications' is:\", spec_count)\n",
    "    return spec_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2467,
   "metadata": {},
   "outputs": [],
   "source": [
    "def strip_spec_list_item(item):\n",
    "    index = item.index(\":\")\n",
    "    return item[index + 1:].strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2468,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_single_specification(html_content, pageid=None):\n",
    "    # Finds the first specification within any given HTML code\n",
    "\n",
    "    spec_dict = {\n",
    "        \"production\":None,\n",
    "        \"type\":None,\n",
    "        \"caliber\":None,\n",
    "        \"capacity\":None,\n",
    "        \"fire_modes\":None\n",
    "    }\n",
    "\n",
    "    soup = BeautifulSoup(html_content, 'html.parser')\n",
    "\n",
    "    # Find all h1 headers in the content\n",
    "    headers = soup.find_all(\"h1\")\n",
    "\n",
    "    if (headers is None or len(headers) == 0):\n",
    "        if pageid is not None:\n",
    "            print(f\"ERROR: get_first_specification(): {pageid} does not contain any headers!\")\n",
    "            return\n",
    "\n",
    "    # Page Title\n",
    "    title = headers[0].text\n",
    "\n",
    "    # Find the first Element with the Specifications id\n",
    "    span = soup.find(id = \"Specifications\")\n",
    "    if span is None:\n",
    "        print(\"ERROR: get_first_specification(): No <span> tag with id = 'Specifications' was found!\")\n",
    "        return\n",
    "\n",
    "    spec_lists = span.parent.find_next_siblings(\"ul\")\n",
    "\n",
    "    # Each spec row is its own unordered list with only a single list item\n",
    "    if spec_lists is None:\n",
    "        print(\"ERROR: get_first_specification(): No <ul> tags were found!\")\n",
    "        return\n",
    "\n",
    "    specifications = [li.text for ul in spec_lists for li in ul.find_all('li')]\n",
    "\n",
    "    if specifications is None:\n",
    "        print(\"ERROR: get_first_specification(): No <li> tags were found!\")\n",
    "        return\n",
    "\n",
    "    # Iterate through the list items and set a dict for each\n",
    "    for item in specifications:\n",
    "        if \"Type:\" in item:\n",
    "            spec_dict[\"type\"] = strip_spec_list_item(item)\n",
    "        elif \"Caliber:\" in item:\n",
    "            spec_dict[\"caliber\"] = strip_spec_list_item(item)\n",
    "        elif \"Feed System\" in item:\n",
    "            spec_dict[\"capacity\"] = strip_spec_list_item(item)\n",
    "        elif \"Capacity:\" in item:\n",
    "            spec_dict[\"capacity\"] = strip_spec_list_item(item)\n",
    "        elif \"Fire Modes:\" in item:\n",
    "            spec_dict[\"fire_modes\"] = strip_spec_list_item(item)\n",
    "    \n",
    "    # Initialize with None so we can check later if a value was extracted from the HTML\n",
    "    production = None\n",
    "\n",
    "    # Determine whether a <p> tag containing a date exists\n",
    "    possible_p_tag = span.parent.find_next_sibling()\n",
    "    if possible_p_tag is not None:\n",
    "        if possible_p_tag.name == \"p\" and re.match(r\"\\(\\.*\\d{4}.*\\)\",str(possible_p_tag.text)):\n",
    "            production = possible_p_tag.text\n",
    "            match = re.search(r\"\\(.*(\\d{4})s?\\s*(-\\s|–\\s)(\\d{4}|Present)s?.*\\)\", production)\n",
    "            if match is not None:\n",
    "                production_year = match.group(1).strip()\n",
    "                production_end_year = match.group(3).strip()\n",
    "                production = f\"({production_year} - {production_end_year})\"\n",
    "            # Add it to the specification\n",
    "            spec_dict[\"production\"] = production.rstrip(\"\\n\")\n",
    "        \n",
    "    return spec_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2469,
   "metadata": {},
   "outputs": [],
   "source": [
    "def articles_has_h1_variants(soup):\n",
    "# Some firearm pages have variants (\"Military, Civilian, etc.\") as their h1, instead of different models\n",
    "    if soup.find(id = \"Specifications\") is not None:\n",
    "        first_specification_header = soup.find(id = \"Specifications\").parent\n",
    "        if first_specification_header.name == \"h3\":\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "    else: # If the table of contents has a depth of 3 or more, we also assume variants\n",
    "        toctitle = soup.find(\"div\", class_=\"toctitle\")\n",
    "        if toctitle is not None:\n",
    "            toc = toctitle.find_next_sibling(\"ul\")\n",
    "            regex = re.compile(r'(\\d\\.){2,}\\d')\n",
    "            for li in toc.find_all('li'):\n",
    "                if regex.search(li.text):\n",
    "                    return True\n",
    "            return False\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2470,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_firearms_from_multi(html_content, url, pageid, parentuuid):\n",
    "    # This function splits multi-gun pages at every h1, if it doesn't use h1s as variants, and at every h2, if it does.\n",
    "\n",
    "    soup = BeautifulSoup(html_content, 'html.parser')\n",
    "\n",
    "    firearmtitle = None\n",
    "    content = \"\"\n",
    "    version = None\n",
    "\n",
    "    see_also = soup.find(id = \"See_Also\")\n",
    "    if see_also is not None:\n",
    "        if see_also.parent.name == \"h1\":\n",
    "            see_also.parent.extract()\n",
    "\n",
    "    spec = soup.find(id = \"Specifications\")\n",
    "    if spec is not None:\n",
    "        if spec.parent.name == \"h1\":\n",
    "            h1spec= spec.parent.extract()\n",
    "\n",
    "    if articles_has_h1_variants(soup): # If it has variants in h1...\n",
    "        headers = soup.find_all(\"h1\")\n",
    "        headers.pop(0) #Skip the first one, since its the page heading\n",
    "        for h1 in headers:\n",
    "            version = h1.text\n",
    "            headers2 = h1.find_next_siblings(\"h2\")\n",
    "            for h2 in headers2:\n",
    "                slices = []\n",
    "                slices.append(h2)\n",
    "                firearmtitle = h2.text\n",
    "                content = \"\"\n",
    "                for slice in h2.find_next_siblings():\n",
    "                    if (slice.name == \"h2\" or slice.name == \"h1\"):\n",
    "                        break\n",
    "                    slices.append(slice.extract())\n",
    "                # Now that we have built up our slices of html, it's time to insert\n",
    "                for slice in slices:\n",
    "                    content = content+str(slice)\n",
    "                if (content == \"\" or firearmtitle is None or version is None):\n",
    "                    print(f\"ERROR: generate_firearm_from_multi(): {pageid} produced empty version, content or title!\")\n",
    "                    continue\n",
    "                if firearmtitle in [\"Video Games\", \"Film\", \"Television\", \"Anime\"]:\n",
    "                    print(f\"ERROR: generate_firearm_from_multi(): Version check failed for {pageid}!\")\n",
    "                    continue\n",
    "                print(f\"DEBUG: generate_firearms_from_multi: INSERTing {firearmtitle}, {pageid}, {parentuuid}\")\n",
    "                statement = \"INSERT INTO firearms (firearmurl, parentfirearmid, firearmpageid, firearmpagecontent, firearmtitle, isfamily, firearmversion) VALUES (%s, %s, %s, %s, %s, %s, %s)\"\n",
    "                cursor.execute(statement, (url, parentuuid, pageid, content,  firearmtitle, 'FALSE', version))\n",
    "                \n",
    "    else: # If it doesn't have variants in h1...\n",
    "        headers = soup.find_all(\"h1\")\n",
    "        headers.pop(0) # Skip the first one\n",
    "        for h1 in headers:\n",
    "            slices = []\n",
    "            slices.append(h1)\n",
    "            firearmtitle = h1.text\n",
    "            content = \"\"\n",
    "            for slice in h1.find_next_siblings():\n",
    "                if slice.name == \"h1\":\n",
    "                    break\n",
    "                slices.append(slice.extract())\n",
    "            # Now that we have built up our slices of html, it's time to insert\n",
    "            for slice in slices:\n",
    "                content = content+str(slice)\n",
    "            if (content == \"\" or firearmtitle is None):\n",
    "                print(f\"ERROR: generate_firearm_from_multi(): {pageid} produced empty content or title!\")\n",
    "                continue\n",
    "            if firearmtitle in [\"Video Games\", \"Film\", \"Television\", \"Anime\"]:\n",
    "                print(f\"ERROR: generate_firearm_from_multi(): Version check failed for {pageid}!\")\n",
    "                continue\n",
    "            print(f\"DEBUG: generate_firearms_from_multi(): INSERTing {firearmtitle}, {pageid}, {parentuuid}\")\n",
    "            statement = \"INSERT INTO firearms (firearmurl, parentfirearmid, firearmpageid, firearmpagecontent, firearmtitle, isfamily) VALUES (%s, %s, %s, %s, %s, %s)\"\n",
    "            cursor.execute(statement, (url, parentuuid, pageid, content,  firearmtitle, 'FALSE'))\n",
    "\n",
    "    if articles_has_h1_variants(soup) is None:\n",
    "        print(f\"ERROR: generate_firearm_from_multi(): Version check failed for {pageid}!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2471,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_firearms_from_multis():\n",
    "    statement = \"SELECT * FROM firearms WHERE isfamily = 'True' AND parentfirearmid IS NULL;\"\n",
    "    cursor.execute(statement)\n",
    "    firearms = cursor.fetchall()\n",
    "\n",
    "    for firearm in firearms:\n",
    "        generate_firearms_from_multi(html_content=firearm[4], url=firearm[1], pageid=firearm[3], parentuuid=firearm[0])\n",
    "    cnx.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2472,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_for_family_candidates():\n",
    "# Debugging function\n",
    "    statement = \"SELECT * FROM firearms\"\n",
    "    cursor.execute(statement)\n",
    "    firearms = cursor.fetchall()\n",
    "    \n",
    "    with open('candidates.txt', 'w') as writer:\n",
    "        for firearm in firearms:\n",
    "            if (is_multi_gun_page(pageid=firearm[3]) and firearm[8] == False):\n",
    "                writer.write(f\"{firearm[3]}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2473,
   "metadata": {},
   "outputs": [],
   "source": [
    "def populate_specs_for_singles():\n",
    "    statement = \"SELECT * FROM firearms WHERE isfamily = 'False';\"\n",
    "    cursor.execute(statement)\n",
    "    firearms = cursor.fetchall()\n",
    "\n",
    "    for firearm in firearms:\n",
    "        print(f\"Fetching spec for: {firearm[3]}\")\n",
    "        spec = get_single_specification(html_content=firearm[4], pageid=firearm[3])\n",
    "        if spec is not None:\n",
    "            print(f\"INSERTing: {firearm[3]} specification\")\n",
    "            statement = \"INSERT INTO specifications (firearmid, type, caliber, capacity, firemode, productiontimeframe) VALUES (%s, %s, %s, %s, %s, %s)\"\n",
    "            cursor.execute(statement, (firearm[0], spec[\"type\"], spec[\"caliber\"], spec[\"capacity\"], spec[\"fire_modes\"], spec[\"production\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2474,
   "metadata": {},
   "outputs": [],
   "source": [
    "def populate_specs_for_multies():\n",
    "    # We handle family rows first, trying to determine whether there is a single spec in an h1 tag for the entire page\n",
    "    statement = \"SELECT * FROM firearms WHERE isfamily = 'True' and parentfirearmid IS NULL\"\n",
    "    cursor.execute(statement)\n",
    "    firearms = cursor.fetchall()\n",
    "\n",
    "    for firearm in firearms:\n",
    "        html_content = firearm[4]\n",
    "        soup = BeautifulSoup(html_content, \"html.parser\")\n",
    "        spec_tag = soup.find_next(id = \"Specifications\") # Find the first spec\n",
    "        if spec_tag is not None:\n",
    "            if spec_tag.parent.name == \"h1\": # If it's nested in an h1...\n",
    "                print(f\"DEBUG: populate_specs_for_multies(): Fetching spec for {firearm[3]}\")\n",
    "                spec = get_single_specification(html_content=firearm[4], pageid=firearm[3])\n",
    "                if spec is not None:\n",
    "                    print(f\"DEBUG: populate_specs_for_multies(): INSERTing {firearm[3]} specification\")\n",
    "                    statement = \"INSERT INTO specifications (firearmid, type, caliber, capacity, firemode, productiontimeframe) VALUES (%s, %s, %s, %s, %s, %s)\"\n",
    "                    cursor.execute(statement, (firearm[0], spec[\"type\"], spec[\"caliber\"], spec[\"capacity\"], spec[\"fire_modes\"], spec[\"production\"]))\n",
    "    # Same procedure for the child rows\n",
    "    statement = \"SELECT * FROM firearms WHERE parentfirearmid IS NOT NULL\"\n",
    "    cursor.execute(statement)\n",
    "    firearms = cursor.fetchall()\n",
    "\n",
    "    for firearm in firearms:\n",
    "        print(f\"Fetching spec for: {firearm[3]}\")\n",
    "        spec = get_single_specification(html_content=firearm[4], pageid=firearm[3])\n",
    "        if spec is not None:\n",
    "            print(f\"INSERTing: {firearm[3]} specification\")\n",
    "            statement = \"INSERT INTO specifications (firearmid, type, caliber, capacity, firemode, productiontimeframe) VALUES (%s, %s, %s, %s, %s, %s)\"\n",
    "            cursor.execute(statement, (firearm[0], spec[\"type\"], spec[\"caliber\"], spec[\"capacity\"], spec[\"fire_modes\"], spec[\"production\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2475,
   "metadata": {},
   "outputs": [],
   "source": [
    "def populate_specifications_table():\n",
    "    populate_specs_for_singles()\n",
    "    populate_specs_for_multies()\n",
    "    cnx.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2476,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_dataframe_from_html_table(html_content, table_name, uuid):\n",
    "    # This is used to find and extract the first table (valid names are 'Film' and 'Television' on any given page) and return it as a data frame\n",
    "    if table_name not in [\"Film\", \"Television\"]:\n",
    "        print(f\"ERROR: extract_dataframe_from_html(): table {table_name} not found in list of valid table names!\")\n",
    "        return\n",
    "    soup = BeautifulSoup(html_content, \"html.parser\")\n",
    "    regex = re.compile(fr'^{table_name}(_\\d*)?')\n",
    "    span = soup.find('span', {'id': regex})\n",
    "    if span is None:\n",
    "        print(f\"WARNING: extract_dataframe_from_html_table(): No span with id {table_name} was found in the html content of {uuid}!\")\n",
    "        return None\n",
    "    table = span.parent.find_next_sibling(\"table\")\n",
    "    if table is None:\n",
    "        print(f\"ERROR: extract_dataframe_from_html_table(): No table was found in the html content of {uuid}!\")\n",
    "        return None\n",
    "    just_the_table = str(table)\n",
    "    df = pd.read_html(just_the_table, extract_links='body')\n",
    "    return df[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2477,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_uuid_by_pageid(pageid, table):\n",
    "    # This only works with tables where the pageid is unique, ie. not firearms\n",
    "    if table in [\"tvseries\"]:\n",
    "        uuid = f\"{table}id\"\n",
    "        id = f\"{table}pageid\"\n",
    "    elif table in [\"actors\", \"movies\"]:\n",
    "        singular = table.rstrip(\"s\")\n",
    "        uuid = f\"{singular}id\"\n",
    "        id = f\"{singular}pageid\"\n",
    "    else:\n",
    "        print(f\"ERROR: get_page_content_from_db(): {table} is not a valid table (actors, movies, tvseries)!\")\n",
    "        return None\n",
    "\n",
    "    statement = f\"select {uuid} from {table} where {id} = '{pageid}';\"\n",
    "    cursor.execute(statement)\n",
    "    print(f\"DEBUG: get_uuid_by_pageid(): Fetching uuid for page with id {pageid} from {table}\") # DEBUG\n",
    "    if cursor.rowcount == 1:\n",
    "        return cursor.fetchone()[0]\n",
    "    else:\n",
    "        print(f\"ERROR: get_uuid_by_pageid(): Unexpected number of rows ({cursor.rowcount}) returned while fetching pageid {pageid} from {table}!\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2478,
   "metadata": {},
   "outputs": [],
   "source": [
    "def populate_redirects_table():\n",
    "    statement = \"SELECT * FROM movies WHERE moviepageid != '0'\"\n",
    "    cursor.execute(statement)\n",
    "    movies = cursor.fetchall()\n",
    "\n",
    "    for movie in movies:\n",
    "        redirects = get_redirects_by_pageid(movie[3])\n",
    "        print(f\"DEBUG: populate_redirects_table(): Currently working on redirects for {movie[3]}:{movie[1]}\")\n",
    "\n",
    "        time.sleep(0.1)\n",
    "\n",
    "        if redirects is not None:\n",
    "            for key,value in redirects.items():\n",
    "                statement = \"INSERT INTO redirects (topageid, totitle, frompageid, fromtitle) VALUES (%s, %s, %s, %s)\"\n",
    "                cursor.execute(statement, (movie[3], movie[1], key, value))\n",
    "\n",
    "    cnx.commit()\n",
    "    \n",
    "    statement = \"SELECT * FROM tvseries WHERE tvseriespageid != '0'\"\n",
    "    cursor.execute(statement)\n",
    "    tvseries = cursor.fetchall()\n",
    "\n",
    "    for series in tvseries:\n",
    "        redirects = get_redirects_by_pageid(series[3])\n",
    "        print(f\"DEBUG: populate_redirects_table(): Currently working on redirects for {series[3]}:{series[1]}\")\n",
    "\n",
    "        time.sleep(0.1)\n",
    "\n",
    "        if redirects is not None:\n",
    "            for key,value in redirects.items():\n",
    "                statement = \"INSERT INTO redirects (topageid, totitle, frompageid, fromtitle) VALUES (%s, %s, %s, %s)\"\n",
    "                cursor.execute(statement, (series[3], series[1], key, value))\n",
    "    cnx.commit()\n",
    "\n",
    "    statement = \"SELECT * FROM actors WHERE actorpageid != '0'\"\n",
    "    cursor.execute(statement)\n",
    "    actors = cursor.fetchall()\n",
    "\n",
    "    for actor in actors:\n",
    "        redirects = get_redirects_by_pageid(actor[2])\n",
    "        print(f\"DEBUG: populate_redirects_table(): Currently working on redirects for {actor[2]}:{actor[4]}\")\n",
    "\n",
    "        time.sleep(0.1)\n",
    "\n",
    "        if redirects is not None:\n",
    "            for key,value in redirects.items():\n",
    "                statement = \"INSERT INTO redirects (topageid, totitle, frompageid, fromtitle) VALUES (%s, %s, %s, %s)\"\n",
    "                cursor.execute(statement, (actor[2], actor[4], key, value))\n",
    "\n",
    "    cnx.commit()\n",
    "\n",
    "    # For some actors the MW API does not return redirect pages, so we insert those manually:\n",
    "    statements = [\"INSERT INTO public.redirects (totitle, topageid, fromtitle, frompageid) VALUES('André Holland', '130821', 'Andre Holland', '324440');\",\n",
    "                \"INSERT INTO public.redirects (totitle, topageid, fromtitle, frompageid) VALUES('Ramón Rodríguez', '112054', 'Ramon Rodriguez', '326018');\",\n",
    "                \"INSERT INTO public.redirects (totitle, topageid, fromtitle, frompageid) VALUES('Ramón Franco', '15039', 'Ramon Franco', '146100');\",\n",
    "                \"INSERT INTO public.redirects (totitle, topageid, fromtitle, frompageid) VALUES('Téa Leoni', '90060', 'Tea Leoni', '184140');\",\n",
    "                \"INSERT INTO public.redirects (totitle, topageid, fromtitle, frompageid) VALUES('Kari Wührer', '66589', 'Kari Wuhrer', '202040');\",\n",
    "                \"INSERT INTO public.redirects (totitle, topageid, fromtitle, frompageid) VALUES(NULL, 'Alexander Skarsgård', '56680', 'Alexander Skarsgard', '80196');\"]\n",
    "    \n",
    "    for statement in statement:\n",
    "        cursor.execute(statement)\n",
    "    cnx.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2479,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_to_skip_file(uuid):\n",
    "    with open('skip.csv', 'a', newline='') as file:\n",
    "        # Create a CSV writer object\n",
    "        csv_writer = csv.writer(file)\n",
    "\n",
    "        # Write some rows to the CSV file\n",
    "        csv_writer.writerow([uuid])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2480,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_skip_file():\n",
    "    with open('skip.csv', 'w', newline='') as file:\n",
    "        file.write('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2481,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_from_skip_file(uuid):\n",
    "    with open('skip.csv', 'r') as file:\n",
    "        csv_reader = csv.reader(file)\n",
    "        \n",
    "        for row in csv_reader:\n",
    "        # Check if the search string is in any of the fields\n",
    "            if any(uuid in field for field in row):\n",
    "                return True\n",
    "        return False\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2482,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_dummy_actor():\n",
    "    statement = \"select actorid from actors where actorpageid = '0' and actorname = 'Dummy / Uncredited Extra';\"\n",
    "    cursor.execute(statement)\n",
    "    if cursor.rowcount > 0:\n",
    "        return cursor.fetchone()[0] # Check for possible duplicate, if it already exists, we return the uuid\n",
    "\n",
    "    statement = \"INSERT INTO actors (actorpageid, actorname) VALUES ('0', 'Dummy / Uncredited Extra')\"\n",
    "    cursor.execute(statement)\n",
    "    cnx.commit()\n",
    "    statement = \"select actorid from actors where actorpageid = '0' and actorname = 'Dummy / Uncredited Extra';\"\n",
    "    cursor.execute(statement)\n",
    "    return cursor.fetchone()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2483,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_actor_without_page(name):\n",
    "    statement = \"select actorid from actors where actorpageid = '0' and actorname = %s;\"\n",
    "    cursor.execute(statement, (name,))\n",
    "    if cursor.rowcount > 0:\n",
    "        return cursor.fetchone()[0] # Check for possible duplicate, if it already exists, we return the uuid\n",
    "\n",
    "    statement = \"INSERT INTO actors (actorpageid, actorname) VALUES ('0', %s)\"\n",
    "    cursor.execute(statement, (name,))\n",
    "    cnx.commit()\n",
    "    statement = \"select actorid from actors where actorpageid = '0' and actorname = %s;\"\n",
    "    cursor.execute(statement, (name,))\n",
    "    print(f\"DEBUG: insert_actor_without_page(): INSERTing actor {name}.\")\n",
    "    return cursor.fetchone()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2484,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_movie_without_page(title):\n",
    "    statement = \"select movieid from movies where moviepageid = '0' and movietitle = %s;\"\n",
    "    cursor.execute(statement, (title,))\n",
    "    if cursor.rowcount > 0:\n",
    "        return cursor.fetchone()[0] # Check for possible duplicate, if it already exists, we return the uuid\n",
    "\n",
    "    statement = \"INSERT INTO movies (moviepageid, movietitle) VALUES ('0', %s)\"\n",
    "    cursor.execute(statement, (title,))\n",
    "    cnx.commit()\n",
    "    statement = \"select movieid from movies where moviepageid = '0' and movietitle = %s;\"\n",
    "    cursor.execute(statement, (title,))\n",
    "    print(f\"DEBUG: insert_movie_without_page(): INSERTing movie {title}.\")\n",
    "    return cursor.fetchone()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2485,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_tvseries_without_page(title):\n",
    "    statement = \"select tvseriesid from tvseries where tvseriespageid = '0' and tvseriestitle = %s;\"\n",
    "    cursor.execute(statement, (title,))\n",
    "    if cursor.rowcount > 0:\n",
    "        return cursor.fetchone()[0] # Check for possible duplicate, if it already exists, we return the uuid\n",
    "\n",
    "    statement = \"INSERT INTO tvseries (tvseriespageid, tvseriestitle) VALUES ('0', %s)\"\n",
    "    cursor.execute(statement, (title,))\n",
    "    cnx.commit()\n",
    "    statement = \"select tvseriesid from tvseries where tvseriespageid = '0' and tvseriestitle = %s;\"\n",
    "    cursor.execute(statement, (title,))\n",
    "    print(f\"DEBUG: insert_tvseries_without_page(): INSERTing tvseries {title}.\")\n",
    "    return cursor.fetchone()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2486,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_redirect_pageid(pageid):\n",
    "    # Look up whether the pageid is a redirect to a different pageid. If not, return it unchanged\n",
    "    statement = \"SELECT topageid FROM redirects WHERE frompageid = %s\"\n",
    "    cursor.execute(statement, (pageid,))\n",
    "    if cursor.rowcount == 1:\n",
    "        return cursor.fetchone()[0]\n",
    "    else:\n",
    "        return pageid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2487,
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_disambiguation_page(title, date):\n",
    "    # url must take the form of '/wiki/Elke_Sommer'\n",
    "    title = title.replace(\" \", \"_\")\n",
    "    url = f\"/wiki/{title}_({date})\"\n",
    "    return get_page_id_by_url(url, \"json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2488,
   "metadata": {},
   "outputs": [],
   "source": [
    "def populate_movies_actors_firearms_table(dummy_uuid):\n",
    "\n",
    "    statement = \"SELECT * FROM firearms ORDER BY firearmpageid ASC\"\n",
    "    cursor.execute(statement)\n",
    "    firearms = cursor.fetchall()\n",
    "\n",
    "    for firearm in firearms:\n",
    "        uuid = firearm[0]\n",
    "        html = get_page_content_from_db_by_uuid(uuid, \"firearms\")\n",
    "        df = extract_dataframe_from_html_table(html, \"Film\", uuid)\n",
    "        if df is None:\n",
    "            continue\n",
    "        \n",
    "        print(f\"DEBUG: populate_movies_actors_firearms_table(): Currently working on appearances of {uuid}\")\n",
    "        if read_from_skip_file(uuid):\n",
    "            print(\"Skipping...\")\n",
    "            continue\n",
    "\n",
    "        # Columns don't have consistent naming, so we have do go through this and match them with regex\n",
    "        title_col_name = actor_col_name = character_col_name = note_col_name = date_col_name = None\n",
    "\n",
    "        title_regex = re.compile('.*(Title|Film|Movie|Titla).*', re.IGNORECASE)\n",
    "        actor_regex = re.compile('.*Actor.*', re.IGNORECASE)\n",
    "        character_regex = re.compile('.*(Character|Charcter).*', re.IGNORECASE)\n",
    "        note_regex = re.compile('.*(Note|Notation).*', re.IGNORECASE)\n",
    "        date_regex = re.compile('.*(Date|Year).*', re.IGNORECASE)\n",
    "\n",
    "        for col_name in df.columns:\n",
    "            if title_regex.match(col_name):\n",
    "                title_col_name = col_name\n",
    "            elif actor_regex.match(col_name):\n",
    "                actor_col_name = col_name\n",
    "            elif character_regex.match(col_name):\n",
    "                character_col_name = col_name\n",
    "            elif note_regex.match(col_name):\n",
    "                note_col_name = col_name\n",
    "            elif date_regex.match(col_name):\n",
    "                date_col_name = col_name\n",
    "        \n",
    "        if any(var is None for var in [title_col_name, actor_col_name, character_col_name, note_col_name, date_col_name]):\n",
    "            print(f\"WARNING: populate_movies_actors_firearms_table(): The html content in '{uuid}' has one or more unmatched columns in its 'Film' table\")\n",
    "\n",
    "        # Extract the row values and INSERT them\n",
    "        for i in range(len(df.index)):\n",
    "            title = actor = character = note = date = \"NULL\"\n",
    "            title = (df[title_col_name][i])[0]\n",
    "            title_link = (df[title_col_name][i])[1]\n",
    "            if actor_col_name is not None:\n",
    "                actor = (df[actor_col_name][i])[0]\n",
    "                actor_link = (df[actor_col_name][i])[1]\n",
    "            character = (df[character_col_name][i])[0]\n",
    "            if note_col_name is not None:\n",
    "                note = (df[note_col_name][i])[0]\n",
    "            if type(df[date_col_name][i]) == float: # This applies if the page author used rowspan but forgot to include an empty note column\n",
    "                match = re.match(r\"\\d{4}\", note)\n",
    "                if match:\n",
    "                    date = note\n",
    "            else:\n",
    "                date = (df[date_col_name][i])[0]\n",
    "\n",
    "            # Page id's can be assigned using the second element of each tuple, which may contain an html link found in each cell.\n",
    "            # This is only attempted when the actor and title columns actually contain a valid title or actor.\n",
    "            if (not(pd.isna(actor) or actor is None)) and (actor not in actor_false_positives): # Actor name is valid\n",
    "                if (actor_link is not None and actor_link != \"\" and \"redlink=1\" not in actor_link): # Actor name is linked to an IMFDB wiki page\n",
    "                    actor_pageid = get_page_id_by_url(actor_link,\"json\")\n",
    "                    actor_pageid = get_redirect_pageid(actor_pageid) # Check for redirect page id\n",
    "                    actor_uuid = get_uuid_by_pageid(actor_pageid, \"actors\")\n",
    "                else: # If we have a valid actor name, but it is not linked to a page, we insert the actor into the database with pageid 0\n",
    "                    actor_uuid = insert_actor_without_page(actor)\n",
    "            \n",
    "            if not (pd.isna(title) or title == \"\" or title is None): # Movie title is not blank\n",
    "                if (title_link is not None and title_link != \"\" and \"redlink=1\" not in title_link): # Movie title is linked to an IMFDB wiki page\n",
    "                    title_pageid = get_page_id_by_url(title_link,\"json\") \n",
    "                    title_pageid = get_redirect_pageid(title_pageid) # Check for redirect page id        \n",
    "                    title_uuid = get_uuid_by_pageid(title_pageid, \"movies\")\n",
    "                else: # If we have a movie title that's not blank, but it is not linked to a page, we insert the movie into the database with pageid 0\n",
    "                    title_uuid = insert_movie_without_page(title)\n",
    "\n",
    "            # Check if the title_uuid points to a disambiguation page\n",
    "            if is_disambiguation_page(title_link):\n",
    "                title_uuid = get_uuid_by_pageid(handle_disambiguation_page(title, date), \"movies\")\n",
    "            \n",
    "            # Some of the values may be NaN. We set those to NULL\n",
    "            if pd.isna(title) or title == \"\" or title is None:\n",
    "                title_uuid = None\n",
    "            if pd.isna(actor) or actor == \"\" or actor is None or actor in actor_false_positives:\n",
    "                actor_uuid = dummy_uuid\n",
    "            if pd.isna(character) or character == \"\":\n",
    "                character = None\n",
    "            if pd.isna(note) or note == \"\":\n",
    "                note = None\n",
    "            if pd.isna(date) or date == \"\":\n",
    "                date = None\n",
    "            else:\n",
    "                date = int(date)\n",
    "\n",
    "            # If after error handling the the title_uuid is can still not be determined, we skip the table row\n",
    "            if title_uuid == \"\" or title_uuid is None:\n",
    "                print(f\"WARNING: populate_movies_actors_firearms_table(): Skipping entire table row {firearm[3]} appearence in {title} used by {actor}!\")\n",
    "                continue\n",
    "\n",
    "            print(f\"DEBUG: INSERTing populate_movies_actors_firearms_table(): {firearm[3]} appearence in {title} used by {actor} in {date}\")\n",
    "            statement = \"INSERT INTO movies_actors_firearms (movieid, firearmid, character, note, year, actorid) VALUES (%s, %s, %s, %s, %s, %s)\"\n",
    "            cursor.execute(statement, (title_uuid, uuid, character, note, date, actor_uuid))\n",
    "        cnx.commit()\n",
    "        write_to_skip_file(uuid)\n",
    "    cnx.commit()\n",
    "    clear_skip_file()\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2489,
   "metadata": {},
   "outputs": [],
   "source": [
    "def populate_tvseries_actors_firearms_table(dummy_uuid):\n",
    "\n",
    "    statement = \"SELECT * FROM firearms ORDER BY firearmpageid ASC\"\n",
    "    cursor.execute(statement)\n",
    "    firearms = cursor.fetchall()\n",
    "\n",
    "    for firearm in firearms:\n",
    "        uuid = firearm[0]\n",
    "        print(f\"DEBUG: populate_tvseries_actors_firearms_table(): Currently working on appearances of {uuid}\")\n",
    "        html = get_page_content_from_db_by_uuid(uuid, \"firearms\")\n",
    "        df = extract_dataframe_from_html_table(html, \"Television\", uuid)\n",
    "        if df is None:\n",
    "            continue\n",
    "        \n",
    "        if read_from_skip_file(uuid):\n",
    "            print(\"Skipping...\")\n",
    "            continue\n",
    "\n",
    "        # Columns don't have consistent naming, so we have do go through this and match them with regex\n",
    "        title_col_name = actor_col_name = character_col_name = note_col_name = date_col_name = None\n",
    "\n",
    "        title_regex = re.compile('.*(Title|Series|Show|Serie|Titla).*', re.IGNORECASE)\n",
    "        actor_regex = re.compile('.*Actor.*', re.IGNORECASE)\n",
    "        character_regex = re.compile('.*(Character|Charcter).*', re.IGNORECASE)\n",
    "        note_regex = re.compile('.*(Note|Notation|Episode|Episodes).*', re.IGNORECASE)\n",
    "        date_regex = re.compile('.*(Date|Year|Air|Run).*', re.IGNORECASE)\n",
    "\n",
    "        for col_name in df.columns:\n",
    "            if title_regex.match(col_name):\n",
    "                title_col_name = col_name\n",
    "            elif actor_regex.match(col_name):\n",
    "                actor_col_name = col_name\n",
    "            elif character_regex.match(col_name):\n",
    "                character_col_name = col_name\n",
    "            elif note_regex.match(col_name):\n",
    "                note_col_name = col_name\n",
    "            elif date_regex.match(col_name):\n",
    "                date_col_name = col_name\n",
    "        \n",
    "        if any(var is None for var in [title_col_name, actor_col_name, character_col_name, note_col_name, date_col_name]):\n",
    "            print(f\"WARNING: populate_tvseries_actors_firearms_table(): The html content in '{uuid}' has one or more unmatched columns in its 'Television' table\")\n",
    "\n",
    "        # Extract the row values and INSERT them\n",
    "        for i in range(len(df.index)):\n",
    "            title = actor = character = note = date = \"NULL\"\n",
    "            title = (df[title_col_name][i])[0]\n",
    "            title_link = (df[title_col_name][i])[1]\n",
    "            if actor_col_name is not None:\n",
    "                actor = (df[actor_col_name][i])[0]\n",
    "                actor_link = (df[actor_col_name][i])[1]\n",
    "            character = (df[character_col_name][i])[0]\n",
    "            if note_col_name is not None:\n",
    "                note = (df[note_col_name][i])[0]\n",
    "            if type(df[date_col_name][i]) == float: # This applies if the page author used rowspan but forgot to include an empty note column\n",
    "                match = re.match(r\"\\d{4}\", note)\n",
    "                if match:\n",
    "                    date = note\n",
    "            else:\n",
    "                date = (df[date_col_name][i])[0]\n",
    "\n",
    "            # Page id's can be assigned using the second element of each tuple, which may contain an html link found in each cell.\n",
    "            # This is only attempted when the actor and title columns actually contain a valid title or actor.\n",
    "            if (not(pd.isna(actor) or actor is None)) and (actor not in actor_false_positives): # Actor name is valid\n",
    "                if (actor_link is not None and actor_link != \"\" and \"redlink=1\" not in actor_link): # Actor name is linked to an IMFDB wiki page\n",
    "                    actor_pageid = get_page_id_by_url(actor_link,\"json\")\n",
    "                    actor_pageid = get_redirect_pageid(actor_pageid) # Check for redirect page id\n",
    "                    actor_uuid = get_uuid_by_pageid(actor_pageid, \"actors\")\n",
    "                else: # If we have a valid actor name, but it is not linked to a page, we insert the actor into the database with pageid 0\n",
    "                    actor_uuid = insert_actor_without_page(actor)\n",
    "            \n",
    "            if not (pd.isna(title) or title == \"\" or title is None): # Series title is not blank\n",
    "                if (title_link is not None and title_link != \"\" and \"redlink=1\" not in title_link): # Series title is linked to an IMFDB wiki page\n",
    "                    title_pageid = get_page_id_by_url(title_link,\"json\") \n",
    "                    title_pageid = get_redirect_pageid(title_pageid) # Check for redirect page id        \n",
    "                    title_uuid = get_uuid_by_pageid(title_pageid, \"tvseries\")\n",
    "                else: # If we have a series title that's not blank, but it is not linked to a page, we insert the series into the database with pageid 0\n",
    "                    title_uuid = insert_tvseries_without_page(title)\n",
    "\n",
    "            # Check if the title_uuid points to a disambiguation page\n",
    "            if is_disambiguation_page(title_link):\n",
    "                title_uuid = get_uuid_by_pageid(handle_disambiguation_page(title, date), \"tvseries\")\n",
    "            \n",
    "            # Some of the values may be NaN. We set those to NULL\n",
    "            if pd.isna(title) or title == \"\" or title is None:\n",
    "                title_uuid = None\n",
    "            if pd.isna(actor) or actor == \"\" or actor is None or actor in actor_false_positives:\n",
    "                actor_uuid = dummy_uuid\n",
    "            if pd.isna(character) or character == \"\":\n",
    "                character = None\n",
    "            if pd.isna(note) or note == \"\":\n",
    "                note = None\n",
    "            if pd.isna(date) or date == \"\":\n",
    "                date = None\n",
    "\n",
    "            # If after error handling the the title_uuid is can still not be determined, we skip the table row\n",
    "            if title_uuid == \"\" or title_uuid is None:\n",
    "                print(f\"WARNING: populate_tvseries_actors_firearms_table(): Skipping entire table row {firearm[3]} appearence in {title} used by {actor}!\")\n",
    "                continue\n",
    "            \n",
    "            #print(f\"Link: {actor_link}\\npageid: {actor_pageid}\\nuuid: {actor_uuid}\")\n",
    "            print(actor_link)\n",
    "            print(actor_pageid)\n",
    "            print(actor_uuid)\n",
    "            print(f\"DEBUG: INSERTing populate_tvseries_actors_firearms_table(): {firearm[3]} appearence in {title} used by {actor} in {date}\")\n",
    "            statement = \"INSERT INTO tvseries_actors_firearms (tvseriesid, firearmid, character, note, year, actorid) VALUES (%s, %s, %s, %s, %s, %s)\"\n",
    "            cursor.execute(statement, (title_uuid, uuid, character, note, date, actor_uuid))\n",
    "        cnx.commit()\n",
    "        write_to_skip_file(uuid)\n",
    "    cnx.commit()\n",
    "    clear_skip_file()\n",
    "    return"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Corner and edge cases:<h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2490,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Corner-case handling:\n",
    "\n",
    "# X HK416 second variant has full html for some reason ()\n",
    "# X Author of Flammenwerfer 35 page is retarded and can't spell table headers right\n",
    "# X Same for DefTech 37mm GL\n",
    "# X Film and Tele tables have Notes only as an option\n",
    "# X Film and tele tables may sometimes be in Spanish\n",
    "# X The notes column may contain the string \"Note\" || \"Notes\" || \"Notation\" || Notations\n",
    "# X actors my be NaN in df\n",
    "# X https://www.imfdb.org/index.php?curid=62 has just a single Spec at the beginning of the page\n",
    "# X Child guns are currently NULL in isfictional column. -> isfictional should default to false\n",
    "# X https://www.imfdb.org/index.php?curid=464719 Sage BML-37 has a table of contents despite being a single\n",
    "# ! https://www.imfdb.org/index.php?curid=348107 HK AG Grenade Launchers are a weird mix of versioned and non-versioned, ie live-fire models are non-versioned, non-firing replicas are versioned\n",
    "# X https://www.imfdb.org/index.php?curid=3564 SIG P210 has its Video Game table nested in the Television segment\n",
    "# X https://www.imfdb.org/index.php?curid=314208 Flintlock Musket has a table of contents despite being a single\n",
    "# X Firearms may appear in a medium, but used by an unnamed actor or extra. Solution: Unnamed extra dummy actor\n",
    "# X Movie pages may have redirects example: https://www.imfdb.org/index.php?curid=14246 (pageid in DB), https://www.imfdb.org/index.php?curid=26085 (pageid in html table)\n",
    "# X TVSeries and movie may not have a linked page or may have a redlink, despite being valid titles\n",
    "# X Actors also have redirects. See Brandon Faser\n",
    "# X https://www.imfdb.org/index.php?curid=397370 The movie Weekend leads to a disambiguation page\n",
    "# X https://www.imfdb.org/index.php?curid=10193 The Modern Family (series) entries are listed in the Film table\n",
    "# X There are a metric crap-ton of movie pages that are a) missing in the movies category and therefore don't exist in the local database b) lead to disambiguation pages and are therefore resolved to an\n",
    "# incorrect page id. Solution: Rewrite the junction table function to commit after every gun, write uuids of finished guns into a file and skip them during next execution.\n",
    "# X skip csv must be deleted between populating junction tables!!\n",
    "# X \"False positive\" missing actors: '.', 'Various', 'Uncredited', 'Danish nazis and resistance fighters' to be added to both junction table checks\n",
    "# X Some deceased actors are not in the actors category\n",
    "# X Some redirect pages are not provided by the API and have to be added manually\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Main<h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2491,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2491,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### We do stuff here: ###\n",
    "\n",
    "#Populate the database skeleton (~250min Runtime):\n",
    "#populate_actors_table()\n",
    "#populate_movies_table()\n",
    "#populate_tvseries_table()\n",
    "#populate_firearms_table_minimally()\n",
    "\n",
    "#Finalize the firearms table (~2min Runtime):\n",
    "#update_firearms_isfictional()\n",
    "#update_firearms_isfamily()\n",
    "#generate_firearms_from_multis()\n",
    "\n",
    "# Populate the specifications table (~2min Runtime): \n",
    "#populate_specifications_table() \n",
    "\n",
    "# Collect redirects (~202min Runtime):\n",
    "#populate_redirects_table()\n",
    "\n",
    "# Populate junction tables:\n",
    "#update_firearm_html_by_uuid('a1ffb406-1949-4474-9f38-a47a8eedda70')\n",
    "dummy_uuid = insert_dummy_actor()\n",
    "#populate_movies_actors_firearms_table(dummy_uuid)\n",
    "populate_tvseries_actors_firearms_table(dummy_uuid)\n",
    "\n",
    "# DEBUG\n",
    "#get_page_id_by_url(\"/wiki/Danica_Curcic\",format=\"json\")\n",
    "#get_uuid_by_pageid(\"357707\", \"actors\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2492,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close database connection\n",
    "cursor.close()\n",
    "cnx.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3c7d0a9ef72501f0b5a8ae503bbb8e6cf935eebdbac61688d07a4418e561ffc3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
